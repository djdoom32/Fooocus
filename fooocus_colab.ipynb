{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djdoom32/Fooocus/blob/main/fooocus_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "bc540a7f-1fa5-41df-8c5e-edf50b2fefce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygit2 in /usr/local/lib/python3.11/dist-packages (1.15.1)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pygit2) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.16.0->pygit2) (2.22)\n",
            "Collecting torchsde\n",
            "  Using cached torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.11/dist-packages (from torchsde) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from torchsde) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from torchsde) (2.6.0+cu124)\n",
            "Collecting trampoline>=0.1.2 (from torchsde)\n",
            "  Using cached trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->torchsde)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->torchsde)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->torchsde)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->torchsde)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->torchsde)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->torchsde)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->torchsde)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->torchsde)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->torchsde)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->torchsde)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->torchsde) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->torchsde) (3.0.2)\n",
            "Using cached torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchsde\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchsde-0.2.6 trampoline-0.1.2\n",
            "/content\n",
            "fatal: destination path 'Fooocus' already exists and is not an empty directory.\n",
            "/content/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "Version mismatch for einops: Installed version 0.8.1 does not meet requirement einops==0.8.0\n",
            "Installing requirements\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 8.28MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 7.95MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v4.0.safetensors\n",
            "\n",
            "100% 5.40M/5.40M [00:00<00:00, 115MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:00<00:00, 367MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:37<00:00, 192MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 189MB/s]\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Running on public URL: https://048968d0076315698a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.67 seconds\n",
            "2025-07-16 21:15:00.793212: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752700501.056023    1770 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752700501.126096    1770 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-16 21:15:01.676914: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Started worker with PID 1123\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://048968d0076315698a.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8216837441889749227\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] 1girl, selfie, alpines, smile to viewer, bright, colorful, highly detailed, vivid color, cinematic, elegant, intricate, innocent, complex, glowing, enhanced, inspired, rich, symmetry, fine detail, clear, aesthetic, beautiful, illuminated, epic light, coherent, perfect composition, calm, artistic, positive, emotional, novel, cute, best\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 2.56 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.76 seconds\n",
            "100% 60/60 [00:55<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.36 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-07-16/log.html\n",
            "Generating and saving time: 59.95 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 59.95 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 62.54 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.91 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 635251953967493243\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] 1girl, selfie, alpines, smile to viewer, masterpice, best quality, absurdes, elegant, modern fine classic, cinematic composition, beautiful detailed, sharp ambient illumination, epic light, dynamic background, atmosphere, magic, shiny, highly decorated color, intricate, very coherent, vibrant colors, open symmetry, iconic, cool, elite, surreal, futuristic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1280, 768)\n",
            "Preparation time: 1.21 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.24 seconds\n",
            "100% 60/60 [00:54<00:00,  1.10it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-07-16/log.html\n",
            "Generating and saving time: 58.13 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 58.13 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 59.36 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 9138721650400512686\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] An action shot of a female knight mid-swing in battle, dust and sparks in the air, dramatic motion blur, highly detailed armor, dynamic, full color, elegant, intricate, sharp focus, beautiful, inspired, vibrant, unique, attractive, epic, cinematic, stunning, illuminated, best, creative, fair, winning, pure, cheerful, romantic,, pretty\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1280, 768)\n",
            "Preparation time: 1.14 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.24 seconds\n",
            " 13% 8/60 [00:07<00:49,  1.05it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 8.87 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 10.03 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 4066886303104244918\n",
            "[Parameters] CFG = 1\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] An action shot of a female knight mid-swing in battle, dust and sparks in the air, dramatic motion blur, highly detailed armor, dynamic, intricate, full color, cinematic, extremely aesthetic, sharp focus, fine detail, elegant, epic composition, creative, beautiful, illuminated, deep light, striking, very inspirational, cute, attractive, elite, stunning, daring\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1280, 768)\n",
            "Preparation time: 0.78 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.12 seconds\n",
            "100% 60/60 [00:28<00:00,  2.10it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-07-16/log.html\n",
            "Generating and saving time: 32.34 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 32.34 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 33.14 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.84 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3653525156329874644\n",
            "[Parameters] CFG = 5\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] An action shot of a female knight mid-swing in battle, dust and sparks in the air, dramatic motion blur, highly detailed armor, dynamic, intricate, strong, cinematic light, elegant, sharp focus, great composition, open balance, aesthetic, very inspirational, shiny, inspiring, bright, deep color, inspired, vibrant, illuminated, epic, stunning, brilliant, amazing\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1280, 768)\n",
            "Preparation time: 1.13 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.14 seconds\n",
            " 23% 14/60 [00:13<00:43,  1.06it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 14.30 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 15.45 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 3060516277629160408\n",
            "[Parameters] CFG = 5\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] An action shot of a female knight mid-swing in battle, dust and sparks in the air, dramatic motion blur, highly detailed armor, dynamic, heroic, vivid, coherent, cool, light, strong, saturated colors, aesthetic, magic, mystical, winning, fine detail, pretty, inspiring, emotional, vibrant, artistic, complex, intricate, elite, cinematic, imposing\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1280, 768)\n",
            "Preparation time: 1.13 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.13 seconds\n",
            "100% 30/30 [00:27<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-07-16/log.html\n",
            "Generating and saving time: 31.36 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 31.36 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 32.51 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.82 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 507640444159602114\n",
            "[Parameters] CFG = 5\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] An action shot of a female knight mid-swing in battle, dust and sparks in the air, dramatic motion blur, highly detailed armor. she habe very big boobs, cinematic light, dynamic background, beautiful composition, intricate, elegant, confident, sharp focus, great special detail, professional fine still, stunning, awesome, perfect, full color, attractive, creative, amazing\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1280, 768)\n",
            "Preparation time: 1.14 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.13 seconds\n",
            "  0% 0/30 [00:00<?, ?it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 2.00 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 3.17 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 2862909743678856435\n",
            "[Parameters] CFG = 5\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] An action shot of a female knight mid-swing in battle, dust and sparks in the air, dramatic motion blur, highly detailed armor. she have very big boobs, stunning full exposed beautiful amazing, delicate, intricate, elegant, creative, cool, fascinating, confident, passionate, inspired, extremely attractive, pretty, inspiring, colorful, deep background, shiny, excellent composition\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1280, 768)\n",
            "Preparation time: 1.11 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.10 seconds\n",
            "100% 30/30 [00:28<00:00,  1.04it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-07-16/log.html\n",
            "Generating and saving time: 32.63 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 32.63 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 33.77 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "Loaded preset: /content/Fooocus/presets/pony_v6.json\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/ponyDiffusionV6XL.safetensors\" to /content/Fooocus/models/checkpoints/ponyDiffusionV6XL.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [01:16<00:00, 90.9MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/ponyDiffusionV6XL_vae.safetensors\" to /content/Fooocus/models/vae/ponyDiffusionV6XL_vae.safetensors\n",
            "\n",
            "100% 319M/319M [00:02<00:00, 115MB/s]\n",
            "Loaded preset: /content/Fooocus/presets/pony_v6.json\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 4043881153955143728\n",
            "[Parameters] CFG = 7\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "Leftover VAE keys ['model_ema.decay', 'model_ema.num_updates']\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['first_stage_model.decoder.conv_in.bias', 'first_stage_model.decoder.conv_in.weight', 'first_stage_model.decoder.conv_out.bias', 'first_stage_model.decoder.conv_out.weight', 'first_stage_model.decoder.mid.attn_1.k.bias', 'first_stage_model.decoder.mid.attn_1.k.weight', 'first_stage_model.decoder.mid.attn_1.norm.bias', 'first_stage_model.decoder.mid.attn_1.norm.weight', 'first_stage_model.decoder.mid.attn_1.proj_out.bias', 'first_stage_model.decoder.mid.attn_1.proj_out.weight', 'first_stage_model.decoder.mid.attn_1.q.bias', 'first_stage_model.decoder.mid.attn_1.q.weight', 'first_stage_model.decoder.mid.attn_1.v.bias', 'first_stage_model.decoder.mid.attn_1.v.weight', 'first_stage_model.decoder.mid.block_1.conv1.bias', 'first_stage_model.decoder.mid.block_1.conv1.weight', 'first_stage_model.decoder.mid.block_1.conv2.bias', 'first_stage_model.decoder.mid.block_1.conv2.weight', 'first_stage_model.decoder.mid.block_1.norm1.bias', 'first_stage_model.decoder.mid.block_1.norm1.weight', 'first_stage_model.decoder.mid.block_1.norm2.bias', 'first_stage_model.decoder.mid.block_1.norm2.weight', 'first_stage_model.decoder.mid.block_2.conv1.bias', 'first_stage_model.decoder.mid.block_2.conv1.weight', 'first_stage_model.decoder.mid.block_2.conv2.bias', 'first_stage_model.decoder.mid.block_2.conv2.weight', 'first_stage_model.decoder.mid.block_2.norm1.bias', 'first_stage_model.decoder.mid.block_2.norm1.weight', 'first_stage_model.decoder.mid.block_2.norm2.bias', 'first_stage_model.decoder.mid.block_2.norm2.weight', 'first_stage_model.decoder.norm_out.bias', 'first_stage_model.decoder.norm_out.weight', 'first_stage_model.decoder.up.0.block.0.conv1.bias', 'first_stage_model.decoder.up.0.block.0.conv1.weight', 'first_stage_model.decoder.up.0.block.0.conv2.bias', 'first_stage_model.decoder.up.0.block.0.conv2.weight', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.0.block.0.norm1.bias', 'first_stage_model.decoder.up.0.block.0.norm1.weight', 'first_stage_model.decoder.up.0.block.0.norm2.bias', 'first_stage_model.decoder.up.0.block.0.norm2.weight', 'first_stage_model.decoder.up.0.block.1.conv1.bias', 'first_stage_model.decoder.up.0.block.1.conv1.weight', 'first_stage_model.decoder.up.0.block.1.conv2.bias', 'first_stage_model.decoder.up.0.block.1.conv2.weight', 'first_stage_model.decoder.up.0.block.1.norm1.bias', 'first_stage_model.decoder.up.0.block.1.norm1.weight', 'first_stage_model.decoder.up.0.block.1.norm2.bias', 'first_stage_model.decoder.up.0.block.1.norm2.weight', 'first_stage_model.decoder.up.0.block.2.conv1.bias', 'first_stage_model.decoder.up.0.block.2.conv1.weight', 'first_stage_model.decoder.up.0.block.2.conv2.bias', 'first_stage_model.decoder.up.0.block.2.conv2.weight', 'first_stage_model.decoder.up.0.block.2.norm1.bias', 'first_stage_model.decoder.up.0.block.2.norm1.weight', 'first_stage_model.decoder.up.0.block.2.norm2.bias', 'first_stage_model.decoder.up.0.block.2.norm2.weight', 'first_stage_model.decoder.up.1.block.0.conv1.bias', 'first_stage_model.decoder.up.1.block.0.conv1.weight', 'first_stage_model.decoder.up.1.block.0.conv2.bias', 'first_stage_model.decoder.up.1.block.0.conv2.weight', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.1.block.0.norm1.bias', 'first_stage_model.decoder.up.1.block.0.norm1.weight', 'first_stage_model.decoder.up.1.block.0.norm2.bias', 'first_stage_model.decoder.up.1.block.0.norm2.weight', 'first_stage_model.decoder.up.1.block.1.conv1.bias', 'first_stage_model.decoder.up.1.block.1.conv1.weight', 'first_stage_model.decoder.up.1.block.1.conv2.bias', 'first_stage_model.decoder.up.1.block.1.conv2.weight', 'first_stage_model.decoder.up.1.block.1.norm1.bias', 'first_stage_model.decoder.up.1.block.1.norm1.weight', 'first_stage_model.decoder.up.1.block.1.norm2.bias', 'first_stage_model.decoder.up.1.block.1.norm2.weight', 'first_stage_model.decoder.up.1.block.2.conv1.bias', 'first_stage_model.decoder.up.1.block.2.conv1.weight', 'first_stage_model.decoder.up.1.block.2.conv2.bias', 'first_stage_model.decoder.up.1.block.2.conv2.weight', 'first_stage_model.decoder.up.1.block.2.norm1.bias', 'first_stage_model.decoder.up.1.block.2.norm1.weight', 'first_stage_model.decoder.up.1.block.2.norm2.bias', 'first_stage_model.decoder.up.1.block.2.norm2.weight', 'first_stage_model.decoder.up.1.upsample.conv.bias', 'first_stage_model.decoder.up.1.upsample.conv.weight', 'first_stage_model.decoder.up.2.block.0.conv1.bias', 'first_stage_model.decoder.up.2.block.0.conv1.weight', 'first_stage_model.decoder.up.2.block.0.conv2.bias', 'first_stage_model.decoder.up.2.block.0.conv2.weight', 'first_stage_model.decoder.up.2.block.0.norm1.bias', 'first_stage_model.decoder.up.2.block.0.norm1.weight', 'first_stage_model.decoder.up.2.block.0.norm2.bias', 'first_stage_model.decoder.up.2.block.0.norm2.weight', 'first_stage_model.decoder.up.2.block.1.conv1.bias', 'first_stage_model.decoder.up.2.block.1.conv1.weight', 'first_stage_model.decoder.up.2.block.1.conv2.bias', 'first_stage_model.decoder.up.2.block.1.conv2.weight', 'first_stage_model.decoder.up.2.block.1.norm1.bias', 'first_stage_model.decoder.up.2.block.1.norm1.weight', 'first_stage_model.decoder.up.2.block.1.norm2.bias', 'first_stage_model.decoder.up.2.block.1.norm2.weight', 'first_stage_model.decoder.up.2.block.2.conv1.bias', 'first_stage_model.decoder.up.2.block.2.conv1.weight', 'first_stage_model.decoder.up.2.block.2.conv2.bias', 'first_stage_model.decoder.up.2.block.2.conv2.weight', 'first_stage_model.decoder.up.2.block.2.norm1.bias', 'first_stage_model.decoder.up.2.block.2.norm1.weight', 'first_stage_model.decoder.up.2.block.2.norm2.bias', 'first_stage_model.decoder.up.2.block.2.norm2.weight', 'first_stage_model.decoder.up.2.upsample.conv.bias', 'first_stage_model.decoder.up.2.upsample.conv.weight', 'first_stage_model.decoder.up.3.block.0.conv1.bias', 'first_stage_model.decoder.up.3.block.0.conv1.weight', 'first_stage_model.decoder.up.3.block.0.conv2.bias', 'first_stage_model.decoder.up.3.block.0.conv2.weight', 'first_stage_model.decoder.up.3.block.0.norm1.bias', 'first_stage_model.decoder.up.3.block.0.norm1.weight', 'first_stage_model.decoder.up.3.block.0.norm2.bias', 'first_stage_model.decoder.up.3.block.0.norm2.weight', 'first_stage_model.decoder.up.3.block.1.conv1.bias', 'first_stage_model.decoder.up.3.block.1.conv1.weight', 'first_stage_model.decoder.up.3.block.1.conv2.bias', 'first_stage_model.decoder.up.3.block.1.conv2.weight', 'first_stage_model.decoder.up.3.block.1.norm1.bias', 'first_stage_model.decoder.up.3.block.1.norm1.weight', 'first_stage_model.decoder.up.3.block.1.norm2.bias', 'first_stage_model.decoder.up.3.block.1.norm2.weight', 'first_stage_model.decoder.up.3.block.2.conv1.bias', 'first_stage_model.decoder.up.3.block.2.conv1.weight', 'first_stage_model.decoder.up.3.block.2.conv2.bias', 'first_stage_model.decoder.up.3.block.2.conv2.weight', 'first_stage_model.decoder.up.3.block.2.norm1.bias', 'first_stage_model.decoder.up.3.block.2.norm1.weight', 'first_stage_model.decoder.up.3.block.2.norm2.bias', 'first_stage_model.decoder.up.3.block.2.norm2.weight', 'first_stage_model.decoder.up.3.upsample.conv.bias', 'first_stage_model.decoder.up.3.upsample.conv.weight', 'first_stage_model.encoder.conv_in.bias', 'first_stage_model.encoder.conv_in.weight', 'first_stage_model.encoder.conv_out.bias', 'first_stage_model.encoder.conv_out.weight', 'first_stage_model.encoder.down.0.block.0.conv1.bias', 'first_stage_model.encoder.down.0.block.0.conv1.weight', 'first_stage_model.encoder.down.0.block.0.conv2.bias', 'first_stage_model.encoder.down.0.block.0.conv2.weight', 'first_stage_model.encoder.down.0.block.0.norm1.bias', 'first_stage_model.encoder.down.0.block.0.norm1.weight', 'first_stage_model.encoder.down.0.block.0.norm2.bias', 'first_stage_model.encoder.down.0.block.0.norm2.weight', 'first_stage_model.encoder.down.0.block.1.conv1.bias', 'first_stage_model.encoder.down.0.block.1.conv1.weight', 'first_stage_model.encoder.down.0.block.1.conv2.bias', 'first_stage_model.encoder.down.0.block.1.conv2.weight', 'first_stage_model.encoder.down.0.block.1.norm1.bias', 'first_stage_model.encoder.down.0.block.1.norm1.weight', 'first_stage_model.encoder.down.0.block.1.norm2.bias', 'first_stage_model.encoder.down.0.block.1.norm2.weight', 'first_stage_model.encoder.down.0.downsample.conv.bias', 'first_stage_model.encoder.down.0.downsample.conv.weight', 'first_stage_model.encoder.down.1.block.0.conv1.bias', 'first_stage_model.encoder.down.1.block.0.conv1.weight', 'first_stage_model.encoder.down.1.block.0.conv2.bias', 'first_stage_model.encoder.down.1.block.0.conv2.weight', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.1.block.0.norm1.bias', 'first_stage_model.encoder.down.1.block.0.norm1.weight', 'first_stage_model.encoder.down.1.block.0.norm2.bias', 'first_stage_model.encoder.down.1.block.0.norm2.weight', 'first_stage_model.encoder.down.1.block.1.conv1.bias', 'first_stage_model.encoder.down.1.block.1.conv1.weight', 'first_stage_model.encoder.down.1.block.1.conv2.bias', 'first_stage_model.encoder.down.1.block.1.conv2.weight', 'first_stage_model.encoder.down.1.block.1.norm1.bias', 'first_stage_model.encoder.down.1.block.1.norm1.weight', 'first_stage_model.encoder.down.1.block.1.norm2.bias', 'first_stage_model.encoder.down.1.block.1.norm2.weight', 'first_stage_model.encoder.down.1.downsample.conv.bias', 'first_stage_model.encoder.down.1.downsample.conv.weight', 'first_stage_model.encoder.down.2.block.0.conv1.bias', 'first_stage_model.encoder.down.2.block.0.conv1.weight', 'first_stage_model.encoder.down.2.block.0.conv2.bias', 'first_stage_model.encoder.down.2.block.0.conv2.weight', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.2.block.0.norm1.bias', 'first_stage_model.encoder.down.2.block.0.norm1.weight', 'first_stage_model.encoder.down.2.block.0.norm2.bias', 'first_stage_model.encoder.down.2.block.0.norm2.weight', 'first_stage_model.encoder.down.2.block.1.conv1.bias', 'first_stage_model.encoder.down.2.block.1.conv1.weight', 'first_stage_model.encoder.down.2.block.1.conv2.bias', 'first_stage_model.encoder.down.2.block.1.conv2.weight', 'first_stage_model.encoder.down.2.block.1.norm1.bias', 'first_stage_model.encoder.down.2.block.1.norm1.weight', 'first_stage_model.encoder.down.2.block.1.norm2.bias', 'first_stage_model.encoder.down.2.block.1.norm2.weight', 'first_stage_model.encoder.down.2.downsample.conv.bias', 'first_stage_model.encoder.down.2.downsample.conv.weight', 'first_stage_model.encoder.down.3.block.0.conv1.bias', 'first_stage_model.encoder.down.3.block.0.conv1.weight', 'first_stage_model.encoder.down.3.block.0.conv2.bias', 'first_stage_model.encoder.down.3.block.0.conv2.weight', 'first_stage_model.encoder.down.3.block.0.norm1.bias', 'first_stage_model.encoder.down.3.block.0.norm1.weight', 'first_stage_model.encoder.down.3.block.0.norm2.bias', 'first_stage_model.encoder.down.3.block.0.norm2.weight', 'first_stage_model.encoder.down.3.block.1.conv1.bias', 'first_stage_model.encoder.down.3.block.1.conv1.weight', 'first_stage_model.encoder.down.3.block.1.conv2.bias', 'first_stage_model.encoder.down.3.block.1.conv2.weight', 'first_stage_model.encoder.down.3.block.1.norm1.bias', 'first_stage_model.encoder.down.3.block.1.norm1.weight', 'first_stage_model.encoder.down.3.block.1.norm2.bias', 'first_stage_model.encoder.down.3.block.1.norm2.weight', 'first_stage_model.encoder.mid.attn_1.k.bias', 'first_stage_model.encoder.mid.attn_1.k.weight', 'first_stage_model.encoder.mid.attn_1.norm.bias', 'first_stage_model.encoder.mid.attn_1.norm.weight', 'first_stage_model.encoder.mid.attn_1.proj_out.bias', 'first_stage_model.encoder.mid.attn_1.proj_out.weight', 'first_stage_model.encoder.mid.attn_1.q.bias', 'first_stage_model.encoder.mid.attn_1.q.weight', 'first_stage_model.encoder.mid.attn_1.v.bias', 'first_stage_model.encoder.mid.attn_1.v.weight', 'first_stage_model.encoder.mid.block_1.conv1.bias', 'first_stage_model.encoder.mid.block_1.conv1.weight', 'first_stage_model.encoder.mid.block_1.conv2.bias', 'first_stage_model.encoder.mid.block_1.conv2.weight', 'first_stage_model.encoder.mid.block_1.norm1.bias', 'first_stage_model.encoder.mid.block_1.norm1.weight', 'first_stage_model.encoder.mid.block_1.norm2.bias', 'first_stage_model.encoder.mid.block_1.norm2.weight', 'first_stage_model.encoder.mid.block_2.conv1.bias', 'first_stage_model.encoder.mid.block_2.conv1.weight', 'first_stage_model.encoder.mid.block_2.conv2.bias', 'first_stage_model.encoder.mid.block_2.conv2.weight', 'first_stage_model.encoder.mid.block_2.norm1.bias', 'first_stage_model.encoder.mid.block_2.norm1.weight', 'first_stage_model.encoder.mid.block_2.norm2.bias', 'first_stage_model.encoder.mid.block_2.norm2.weight', 'first_stage_model.encoder.norm_out.bias', 'first_stage_model.encoder.norm_out.weight', 'first_stage_model.post_quant_conv.bias', 'first_stage_model.post_quant_conv.weight', 'first_stage_model.quant_conv.bias', 'first_stage_model.quant_conv.weight', 'cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.04 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/ponyDiffusionV6XL.safetensors\n",
            "VAE loaded: /content/Fooocus/models/vae/ponyDiffusionV6XL_vae.safetensors\n",
            "Request to load LoRAs [] for model [/content/Fooocus/models/checkpoints/ponyDiffusionV6XL.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.94 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 36.08 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            "100% 30/30 [00:31<00:00,  1.06s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-07-16/log.html\n",
            "Generating and saving time: 35.20 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 35.20 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 71.30 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7865 <> https://048968d0076315698a.gradio.live\n"
          ]
        }
      ],
      "source": [
        "!pip install pygit2\n",
        "!pip install torchsde\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}